{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Rent in NYC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "import math\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b583cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Historical monthly average rents by zip code from Zillow from\n",
    "\n",
    "#create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "def download_file(url, directory, filename):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(directory, filename), \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "# Example usage\n",
    "url = \"https://drive.google.com/uc?id=1LdJkhLKTbSfVLSbiZA-S4CF6tLIWKkPj&export=download\"\n",
    "directory = \"data\"\n",
    "filename = \"zillow_rent_data.csv\"\n",
    "\n",
    "download_file(url, directory, filename)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Historical data from NYC Open Data-trees\n",
    "TREE_URL = \"https://data.cityofnewyork.us/resource/5rq2-4hqu.geojson?$$app_token=bGN5ZHzRAwz2VxsMyRVEiycko\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "params = {\n",
    "    \"$where\": \"latitude IS NOT NULL AND longitude IS NOT NULL AND spc_common IS NOT NULL\",\n",
    "    \"$limit\": 50  # Set a limit to ensure all data within the date range is fetched\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.get(TREE_URL,params)\n",
    "\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Save the content of the response to a file\n",
    "    with open(\"tree_census.geojson\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Data downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download data. Status code:\", response.status_code)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0449dcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "## Historical data from NYC Open Data-311complaints\n",
    "# Define the URL of the dataset\n",
    "url = \"https://data.cityofnewyork.us/resource/erm2-nwe9.geojson?$$app_token=bGN5ZHzRAwz2VxsMyRVEiycko\"\n",
    "# Send a GET request to the URL\n",
    "\n",
    "params = {\n",
    "    \"$where\": \"Latitude IS NOT NULL AND created_date >= '2023-02-28T00:00:00.000'\",\n",
    "    \"$limit\": 50  # Set a limit to ensure all data within the date range is fetched\n",
    "}\n",
    "\n",
    "response = requests.get(url,params)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Save the content of the response to a file\n",
    "    with open(\"311_complaints.geojson\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Data downloaded successfully.\")\n",
    "else:\n",
    "    print(\"Failed to download data. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6601633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'queries' created successfully or already exists.\n"
     ]
    }
   ],
   "source": [
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\"\n",
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.makedirs(QUERY_DIRECTORY, exist_ok=True)\n",
    "    print(f\"Directory '{QUERY_DIRECTORY}' created successfully or already exists.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating directory:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load NYC Open Data on 311 complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58708809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 complaints data loaded successfully.\n",
      "  location_state facility_type intersection_street_2      city location_zip  \\\n",
      "0                         None              2 AVENUE  NEW YORK                \n",
      "1                         None        RANDALL AVENUE     BRONX                \n",
      "2                         None       FRANKLIN STREET  NEW YORK                \n",
      "3                         None      EAST    8 STREET  BROOKLYN                \n",
      "4                         None      VALENTINE AVENUE     BRONX                \n",
      "\n",
      "  park_borough            latitude road_ramp        created_date agency  ...  \\\n",
      "0    MANHATTAN   40.78402918520533      None 2024-04-12 01:41:02   NYPD  ...   \n",
      "1        BRONX   40.82509230617025      None 2024-04-12 01:40:51   NYPD  ...   \n",
      "2    MANHATTAN  40.716459431762694      None 2024-04-12 01:39:44    DHS  ...   \n",
      "3     BROOKLYN  40.614994014161276      None 2024-04-12 01:39:26   NYPD  ...   \n",
      "4        BRONX   40.87156933675358      None 2024-04-12 01:38:24   NYPD  ...   \n",
      "\n",
      "                              resolution_description community_board  \\\n",
      "0                                               None    08 MANHATTAN   \n",
      "1                                               None        10 BRONX   \n",
      "2  The Department of Homeless Services has sent a...    01 MANHATTAN   \n",
      "3                                               None     12 BROOKLYN   \n",
      "4                                               None        07 BRONX   \n",
      "\n",
      "  resolution_action_updated_date intersection_street_1 closed_date  \\\n",
      "0            2024-04-12 02:11:29              3 AVENUE         NaT   \n",
      "1                            NaT         SCHLEY AVENUE         NaT   \n",
      "2            2024-04-12 01:43:59        LEONARD STREET         NaT   \n",
      "3                            NaT      EAST    7 STREET         NaT   \n",
      "4            2024-04-12 02:36:21       GRAND CONCOURSE         NaT   \n",
      "\n",
      "  vehicle_type    cross_street_1    borough                landmark  \\\n",
      "0          Van          3 AVENUE  MANHATTAN        EAST   95 STREET   \n",
      "1         None     SCHLEY AVENUE      BRONX           EDISON AVENUE   \n",
      "2         None    LEONARD STREET  MANHATTAN        LAFAYETTE STREET   \n",
      "3         None  EAST    7 STREET   BROOKLYN            RODER AVENUE   \n",
      "4         None   GRAND CONCOURSE      BRONX  BEDFORD PARK BOULEVARD   \n",
      "\n",
      "                     geometry  \n",
      "0  POINT (-73.94865 40.78403)  \n",
      "1  POINT (-73.81957 40.82509)  \n",
      "2  POINT (-74.00233 40.71646)  \n",
      "3  POINT (-73.96699 40.61499)  \n",
      "4  POINT (-73.88721 40.87157)  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_311data(geojson_file):\n",
    "    try:\n",
    "        # Load the GeoJSON file into a GeoDataFrame\n",
    "        gdf = gpd.read_file(geojson_file)\n",
    "        print(\"311 complaints data loaded successfully.\")\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(\"Error loading 311 complaints data:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "geojson_file = \"311_complaints.geojson\"\n",
    "complaints_data = load_311data(geojson_file)\n",
    "\n",
    "# Step 2: Data Inspection\n",
    "print(complaints_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16011366",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process NYC Open Data on 311 complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372d295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unique_key incident_zip        created_date              complaint_type\n",
      "0   60840295        10128 2024-04-12 01:41:02             Noise - Vehicle\n",
      "1   60834920        10465 2024-04-12 01:40:51             Illegal Parking\n",
      "2   60835892        10013 2024-04-12 01:39:44  Homeless Person Assistance\n",
      "3   60834916        11230 2024-04-12 01:39:26             Illegal Parking\n",
      "4   60835776        10458 2024-04-12 01:38:24         Noise - Residential\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   unique_key      50 non-null     object        \n",
      " 1   incident_zip    48 non-null     object        \n",
      " 2   created_date    50 non-null     datetime64[ns]\n",
      " 3   complaint_type  50 non-null     object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 1.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def keep_columns(df, columns_to_keep):\n",
    "    # Select only the specified columns\n",
    "    df = df[columns_to_keep]\n",
    "    return df\n",
    "\n",
    "complaints_data_cleaned = keep_columns(complaints_data, ['unique_key','incident_zip','created_date','complaint_type'])\n",
    "print(complaints_data_cleaned.head())\n",
    "print(complaints_data_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Zipcode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e747100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   ZIPCODE     263 non-null    object  \n",
      " 1   BLDGZIP     263 non-null    object  \n",
      " 2   PO_NAME     263 non-null    object  \n",
      " 3   POPULATION  263 non-null    float64 \n",
      " 4   AREA        263 non-null    float64 \n",
      " 5   STATE       263 non-null    object  \n",
      " 6   COUNTY      263 non-null    object  \n",
      " 7   ST_FIPS     263 non-null    object  \n",
      " 8   CTY_FIPS    263 non-null    object  \n",
      " 9   URL         263 non-null    object  \n",
      " 10  SHAPE_AREA  263 non-null    float64 \n",
      " 11  SHAPE_LEN   263 non-null    float64 \n",
      " 12  geometry    263 non-null    geometry\n",
      "dtypes: float64(4), geometry(1), object(8)\n",
      "memory usage: 26.8+ KB\n",
      "None\n",
      "  ZIPCODE                                           geometry\n",
      "0   11436  POLYGON ((1038098.252 188138.380, 1038141.936 ...\n",
      "1   11213  POLYGON ((1001613.713 186926.440, 1002314.243 ...\n",
      "2   11212  POLYGON ((1011174.276 183696.338, 1011373.584 ...\n",
      "3   11225  POLYGON ((995908.365 183617.613, 996522.848 18...\n",
      "4   11218  POLYGON ((991997.113 176307.496, 992042.798 17...\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   ZIPCODE   263 non-null    object  \n",
      " 1   geometry  263 non-null    geometry\n",
      "dtypes: geometry(1), object(1)\n",
      "memory usage: 4.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_Zipcode_data(shapefile_dir):\n",
    "    # Path to the directory containing the shapefile\n",
    "# Load the shapefile into a GeoDataFrame\n",
    "    gdf = gpd.read_file(shapefile_dir)\n",
    "    return gdf\n",
    "zipcodes=load_Zipcode_data(\"data/nyc_zipcodes.shp\")\n",
    "print(zipcodes.info())\n",
    "\n",
    "def keep_Zipcode_columns(df,columns_to_keep):\n",
    "    df=df[columns_to_keep]\n",
    "    \n",
    "    return df\n",
    "\n",
    "zipcodes_data_cleaned=keep_Zipcode_columns(zipcodes,[\"ZIPCODE\",\"geometry\"])\n",
    "print(zipcodes_data_cleaned.head())\n",
    "print(zipcodes_data_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Zillow Rent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RegionID      SizeRank    RegionName   2015-01-31   2015-02-28  \\\n",
      "count     575.000000    575.000000    575.000000   575.000000   575.000000   \n",
      "mean    87999.222609   1965.786087  52016.845217  1403.794237  1412.462501   \n",
      "std     51370.757623   1901.496671  30635.660443   628.477602   635.431388   \n",
      "min     58627.000000      1.000000   2113.000000   551.829341   549.959262   \n",
      "25%     70823.500000    530.000000  30033.000000  1000.788457  1003.254599   \n",
      "50%     73201.000000   1339.000000  34698.000000  1229.841194  1231.005300   \n",
      "75%     94842.500000   2794.500000  85208.500000  1608.809833  1610.500914   \n",
      "max    417444.000000  12215.000000  98503.000000  5342.134698  5545.637773   \n",
      "\n",
      "        2015-03-31   2015-04-30   2015-05-31   2015-06-30   2015-07-31  ...  \\\n",
      "count   575.000000   575.000000   575.000000   575.000000   575.000000  ...   \n",
      "mean   1422.872980  1434.340943  1444.530315  1454.691224  1463.191322  ...   \n",
      "std     643.096303   650.660652   655.669486   662.678389   666.387341  ...   \n",
      "min     552.157170   554.960823   565.465233   573.144449   575.277202  ...   \n",
      "25%    1013.631471  1024.589052  1030.597286  1041.304242  1047.494024  ...   \n",
      "50%    1235.278096  1251.205800  1259.265848  1264.197386  1267.072253  ...   \n",
      "75%    1629.219264  1650.999553  1666.087466  1677.305015  1681.806377  ...   \n",
      "max    5805.423194  5762.407855  5712.534426  5813.091613  5950.307548  ...   \n",
      "\n",
      "         2023-04-30    2023-05-31    2023-06-30    2023-07-31    2023-08-31  \\\n",
      "count    575.000000    575.000000    575.000000    575.000000    575.000000   \n",
      "mean    2268.139866   2285.594990   2299.685555   2310.370988   2314.175098   \n",
      "std      845.241467    854.772948    869.328044    879.925943    882.142603   \n",
      "min     1007.059458   1005.203783   1010.989462   1021.010933   1041.710607   \n",
      "25%     1789.566788   1802.366592   1803.724157   1808.583044   1797.148632   \n",
      "50%     2042.707683   2066.446052   2068.816703   2083.580958   2080.453529   \n",
      "75%     2513.409775   2531.752232   2551.614729   2571.064774   2576.011762   \n",
      "max    10165.891400  10345.602611  10667.830567  10870.010082  10798.831214   \n",
      "\n",
      "         2023-09-30   2023-10-31   2023-11-30   2023-12-31   2024-01-31  \n",
      "count    575.000000   575.000000   575.000000   575.000000   575.000000  \n",
      "mean    2310.688197  2303.956414  2293.827998  2288.872267  2290.400188  \n",
      "std      873.620427   865.216095   853.430650   848.431534   846.930950  \n",
      "min     1035.785753  1019.024743  1021.478817  1027.969355  1054.737374  \n",
      "25%     1793.349818  1790.476551  1798.480919  1801.923912  1795.178097  \n",
      "50%     2073.744781  2066.049490  2056.236119  2052.843051  2056.546699  \n",
      "75%     2582.737288  2579.546200  2571.329558  2560.133286  2562.828567  \n",
      "max    10098.264573  9677.053659  9499.390217  9655.948887  9657.500000  \n",
      "\n",
      "[8 rows x 112 columns]\n",
      "    RegionID  SizeRank  RegionName RegionType StateName State           City  \\\n",
      "0      91982         1       77494        zip        TX    TX           Katy   \n",
      "2      91940         3       77449        zip        TX    TX           Katy   \n",
      "8      91926        11       77433        zip        TX    TX        Cypress   \n",
      "16     62037        19       11226        zip        NY    NY       New York   \n",
      "18     70829        21       30044        zip        GA    GA  Lawrenceville   \n",
      "\n",
      "                                    Metro        CountyName   2015-01-31  ...  \\\n",
      "0    Houston-The Woodlands-Sugar Land, TX  Fort Bend County  1471.214336  ...   \n",
      "2    Houston-The Woodlands-Sugar Land, TX     Harris County  1285.448996  ...   \n",
      "8    Houston-The Woodlands-Sugar Land, TX     Harris County  1350.951013  ...   \n",
      "16  New York-Newark-Jersey City, NY-NJ-PA      Kings County  1868.105728  ...   \n",
      "18   Atlanta-Sandy Springs-Alpharetta, GA   Gwinnett County  1102.686034  ...   \n",
      "\n",
      "     2023-04-30   2023-05-31   2023-06-30   2023-07-31   2023-08-31  \\\n",
      "0   1843.953065  1853.546220  1860.805060  1873.335787  1879.080480   \n",
      "2   1799.232097  1803.978538  1815.603187  1824.661645  1837.338997   \n",
      "8   1882.654529  1881.873450  1908.720996  1941.138293  1965.196968   \n",
      "16  2613.659650  2633.525698  2662.290709  2679.586231  2693.602946   \n",
      "18  2058.256657  2050.162966  2032.137633  1993.185884  1991.503042   \n",
      "\n",
      "     2023-09-30   2023-10-31   2023-11-30   2023-12-31   2024-01-31  \n",
      "0   1882.092604  1877.636803  1857.636589  1846.701735  1839.654960  \n",
      "2   1837.127291  1822.343233  1809.231267  1813.118556  1830.410884  \n",
      "8   1997.556435  1984.275828  1962.842219  1886.411739  1867.679966  \n",
      "16  2672.819878  2644.929685  2644.410748  2652.155298  2680.780024  \n",
      "18  1935.298976  1946.574119  1920.301442  1987.412100  1995.192319  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 575 entries, 0 to 6479\n",
      "Columns: 118 entries, RegionID to 2024-01-31\n",
      "dtypes: float64(109), int64(3), object(6)\n",
      "memory usage: 534.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_Zillow_Rent_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df=df.dropna()\n",
    "    return df\n",
    "rent_data=load_Zillow_Rent_data(\"zillow_rent_data.csv\")\n",
    "print(rent_data.describe())\n",
    "print(rent_data.head())\n",
    "print(rent_data.info())\n",
    "\n",
    "def drop_not_needed_columns(df,columns):\n",
    "    df = df.drop(columns=columns, errors='ignore')\n",
    "    return df\n",
    "columns_to_drop = [\"SizeRank\", \"RegionType\", \"StateName\",\"State\",\"City\",\"Metro\",\"CountyName\"]\n",
    "rent_data_processed = drop_not_needed_columns(rent_data, columns_to_drop)\n",
    "\n",
    "def drop_columns_before_date(df, date):\n",
    "    # Get the index of the date in the columns\n",
    "    date_index = df.columns.get_loc(date)\n",
    "    \n",
    "    # Select columns from the date onwards\n",
    "    columns_to_keep = df.columns[date_index:]\n",
    "    \n",
    "    return df[columns_to_keep]\n",
    "\n",
    "\n",
    "rent_data_cleaned=pd.merge(drop_columns_before_date(rent_data_processed,\"2022-02-28\"),rent_data_processed[\"RegionName\"],left_index=True, right_index=True)\n",
    "rent_data_cleaned=pd.merge(rent_data_cleaned,rent_data_processed[\"RegionID\"],left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cebf9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2022-02-28   2022-03-31   2022-04-30   2022-05-31   2022-06-30  \\\n",
      "0   1762.262439  1770.552861  1785.325091  1810.321876  1833.942229   \n",
      "2   1721.397080  1742.841518  1764.553406  1744.354038  1743.677698   \n",
      "8   1838.826094  1835.449047  1856.922199  1879.630889  1890.945343   \n",
      "16  2415.357857  2451.406046  2492.544828  2528.553196  2585.077670   \n",
      "18  1871.896033  1909.316349  1903.789149  1937.572633  1945.348547   \n",
      "\n",
      "     2022-07-31   2022-08-31   2022-09-30   2022-10-31   2022-11-30  ...  \\\n",
      "0   1856.062108  1857.089958  1850.251951  1840.882840  1826.146229  ...   \n",
      "2   1781.779706  1845.912781  1847.882750  1827.755137  1788.139921  ...   \n",
      "8   1910.784194  1922.780911  1907.362558  1893.717749  1894.501883  ...   \n",
      "16  2611.357874  2620.821184  2617.559725  2628.648650  2626.115078  ...   \n",
      "18  1978.766635  1980.598434  1979.695761  1983.337417  1957.606126  ...   \n",
      "\n",
      "     2023-06-30   2023-07-31   2023-08-31   2023-09-30   2023-10-31  \\\n",
      "0   1860.805060  1873.335787  1879.080480  1882.092604  1877.636803   \n",
      "2   1815.603187  1824.661645  1837.338997  1837.127291  1822.343233   \n",
      "8   1908.720996  1941.138293  1965.196968  1997.556435  1984.275828   \n",
      "16  2662.290709  2679.586231  2693.602946  2672.819878  2644.929685   \n",
      "18  2032.137633  1993.185884  1991.503042  1935.298976  1946.574119   \n",
      "\n",
      "     2023-11-30   2023-12-31   2024-01-31  RegionName  RegionID  \n",
      "0   1857.636589  1846.701735  1839.654960       77494     91982  \n",
      "2   1809.231267  1813.118556  1830.410884       77449     91940  \n",
      "8   1962.842219  1886.411739  1867.679966       77433     91926  \n",
      "16  2644.410748  2652.155298  2680.780024       11226     62037  \n",
      "18  1920.301442  1987.412100  1995.192319       30044     70829  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 575 entries, 0 to 6479\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   2022-02-28  575 non-null    float64\n",
      " 1   2022-03-31  575 non-null    float64\n",
      " 2   2022-04-30  575 non-null    float64\n",
      " 3   2022-05-31  575 non-null    float64\n",
      " 4   2022-06-30  575 non-null    float64\n",
      " 5   2022-07-31  575 non-null    float64\n",
      " 6   2022-08-31  575 non-null    float64\n",
      " 7   2022-09-30  575 non-null    float64\n",
      " 8   2022-10-31  575 non-null    float64\n",
      " 9   2022-11-30  575 non-null    float64\n",
      " 10  2022-12-31  575 non-null    float64\n",
      " 11  2023-01-31  575 non-null    float64\n",
      " 12  2023-02-28  575 non-null    float64\n",
      " 13  2023-03-31  575 non-null    float64\n",
      " 14  2023-04-30  575 non-null    float64\n",
      " 15  2023-05-31  575 non-null    float64\n",
      " 16  2023-06-30  575 non-null    float64\n",
      " 17  2023-07-31  575 non-null    float64\n",
      " 18  2023-08-31  575 non-null    float64\n",
      " 19  2023-09-30  575 non-null    float64\n",
      " 20  2023-10-31  575 non-null    float64\n",
      " 21  2023-11-30  575 non-null    float64\n",
      " 22  2023-12-31  575 non-null    float64\n",
      " 23  2024-01-31  575 non-null    float64\n",
      " 24  RegionName  575 non-null    int64  \n",
      " 25  RegionID    575 non-null    int64  \n",
      "dtypes: float64(24), int64(2)\n",
      "memory usage: 137.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rent_data_cleaned.head())\n",
    "print(rent_data_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing NYC Open Data on Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nta health zipcode     latitude            nta_name     state trnk_wire  \\\n",
      "0  QN17   Fair   11375  40.72309177        Forest Hills  New York        No   \n",
      "1  QN49   Fair   11357  40.79411067          Whitestone  New York        No   \n",
      "2  BK90   Good   11211  40.71758074   East Williamsburg  New York        No   \n",
      "3  BK90   Good   11211  40.71353749   East Williamsburg  New York        No   \n",
      "4  BK37   Good   11215  40.66677776  Park Slope-Gowanus  New York        No   \n",
      "\n",
      "            y_sp brnch_othe root_grate  ...            address  sidewalk  \\\n",
      "0  202756.768749         No         No  ...  108-005 70 AVENUE  NoDamage   \n",
      "1  228644.837379         No         No  ...   147-074 7 AVENUE    Damage   \n",
      "2  200716.891267         No         No  ...  390 MORGAN AVENUE    Damage   \n",
      "3  199244.253136         No         No  ...  1027 GRAND STREET    Damage   \n",
      "4  182202.425999         No         No  ...       603 6 STREET    Damage   \n",
      "\n",
      "  root_other  created_at borocode block_id trnk_light tree_dbh root_stone  \\\n",
      "0         No  08/27/2015        4   348711         No        3         No   \n",
      "1         No  09/03/2015        4   315986         No       21        Yes   \n",
      "2         No  09/05/2015        3   218365         No        3         No   \n",
      "3         No  09/05/2015        3   217969         No       10        Yes   \n",
      "4         No  08/30/2015        3   223043         No       21        Yes   \n",
      "\n",
      "                     geometry  \n",
      "0  POINT (-73.84422 40.72309)  \n",
      "1  POINT (-73.81868 40.79411)  \n",
      "2  POINT (-73.93661 40.71758)  \n",
      "3  POINT (-73.93446 40.71354)  \n",
      "4  POINT (-73.97598 40.66678)  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 42 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   nta         50 non-null     object  \n",
      " 1   health      50 non-null     object  \n",
      " 2   zipcode     50 non-null     object  \n",
      " 3   latitude    50 non-null     object  \n",
      " 4   nta_name    50 non-null     object  \n",
      " 5   state       50 non-null     object  \n",
      " 6   trnk_wire   50 non-null     object  \n",
      " 7   y_sp        50 non-null     object  \n",
      " 8   brnch_othe  50 non-null     object  \n",
      " 9   root_grate  50 non-null     object  \n",
      " 10  tree_id     50 non-null     object  \n",
      " 11  steward     50 non-null     object  \n",
      " 12  spc_common  50 non-null     object  \n",
      " 13  trnk_other  50 non-null     object  \n",
      " 14  x_sp        50 non-null     object  \n",
      " 15  brnch_ligh  50 non-null     object  \n",
      " 16  problems    50 non-null     object  \n",
      " 17  longitude   50 non-null     object  \n",
      " 18  boro_ct     50 non-null     object  \n",
      " 19  zip_city    50 non-null     object  \n",
      " 20  spc_latin   50 non-null     object  \n",
      " 21  stump_diam  50 non-null     object  \n",
      " 22  boroname    50 non-null     object  \n",
      " 23  st_senate   50 non-null     object  \n",
      " 24  user_type   50 non-null     object  \n",
      " 25  status      50 non-null     object  \n",
      " 26  brnch_shoe  50 non-null     object  \n",
      " 27  curb_loc    50 non-null     object  \n",
      " 28  cncldist    50 non-null     object  \n",
      " 29  guards      50 non-null     object  \n",
      " 30  st_assem    50 non-null     object  \n",
      " 31  cb_num      50 non-null     object  \n",
      " 32  address     50 non-null     object  \n",
      " 33  sidewalk    50 non-null     object  \n",
      " 34  root_other  50 non-null     object  \n",
      " 35  created_at  50 non-null     object  \n",
      " 36  borocode    50 non-null     object  \n",
      " 37  block_id    50 non-null     object  \n",
      " 38  trnk_light  50 non-null     object  \n",
      " 39  tree_dbh    50 non-null     object  \n",
      " 40  root_stone  50 non-null     object  \n",
      " 41  geometry    50 non-null     geometry\n",
      "dtypes: geometry(1), object(41)\n",
      "memory usage: 16.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def load_trees_data(geojson_file):\n",
    "    try:\n",
    "        trees_data = gpd.read_file(geojson_file)\n",
    "        return trees_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Trees data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "geojson_file = \"tree_census.geojson\"\n",
    "trees_data = load_trees_data(geojson_file)\n",
    "\n",
    "# Step 2: Data Inspection\n",
    "if trees_data is not None:\n",
    "    print(trees_data.head())\n",
    "    print(trees_data.info())\n",
    "else:\n",
    "    print(\"Tree data not loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72db63ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tree_id health zipcode status                    geometry  \\\n",
      "0  180683   Fair   11375  Alive  POINT (-73.84422 40.72309)   \n",
      "1  200540   Fair   11357  Alive  POINT (-73.81868 40.79411)   \n",
      "2  204026   Good   11211  Alive  POINT (-73.93661 40.71758)   \n",
      "3  204337   Good   11211  Alive  POINT (-73.93446 40.71354)   \n",
      "4  189565   Good   11215  Alive  POINT (-73.97598 40.66678)   \n",
      "\n",
      "                            spc_latin  \n",
      "0                         Acer rubrum  \n",
      "1                   Quercus palustris  \n",
      "2  Gleditsia triacanthos var. inermis  \n",
      "3  Gleditsia triacanthos var. inermis  \n",
      "4                     Tilia americana  \n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   tree_id    50 non-null     object  \n",
      " 1   health     50 non-null     object  \n",
      " 2   zipcode    50 non-null     object  \n",
      " 3   status     50 non-null     object  \n",
      " 4   geometry   50 non-null     geometry\n",
      " 5   spc_latin  50 non-null     object  \n",
      "dtypes: geometry(1), object(5)\n",
      "memory usage: 2.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trees_data_cleaned = keep_columns(trees_data, ['tree_id', 'health','zipcode','status','geometry','spc_latin'])\n",
    "print(trees_data_cleaned.head())\n",
    "print(trees_data_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358e4b4",
   "metadata": {},
   "source": [
    "## Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9965e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createdb: error: database creation failed: ERROR:  database \"Project_Database\" already exists\n",
      "ERROR:  extension \"postgis\" already exists\n"
     ]
    }
   ],
   "source": [
    "!createdb Project_Database\n",
    "!psql --dbname Project_Database -c 'CREATE EXTENSION postgis;'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8f9e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Users/sfm/anaconda3/lib/python3.11/site-packages (2.9.9)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f617f53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "dbname = \"Project_Database\"\n",
    "user = \"sfm\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "    print(\"Connection successful\")\n",
    "\n",
    "    # Do some operations with the database here\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    print(\"Connection closed\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Unable to connect to the database:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "NYC_zip_codes_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Zip_Code\n",
    "(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    zipcode INTEGER,\n",
    "    geometry GEOMETRY(POINT, 4326)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "ThreeOneOne_complaints_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Complaint\n",
    "(\n",
    "    unique_key SERIAL PRIMARY KEY,\n",
    "    incident_zip INTEGER,\n",
    "    created_date TIMESTAMP,\n",
    "    complaint_type TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "Historical_Average_Rents_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Rent\n",
    "(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    \"2022-02-28\" FLOAT,\n",
    "    \"2022-03-31\" FLOAT,\n",
    "    \"2022-04-30\" FLOAT,\n",
    "    \"2022-05-31\" FLOAT,\n",
    "    \"2022-06-30\" FLOAT,\n",
    "    \"2022-07-31\" FLOAT,\n",
    "    \"2022-08-31\" FLOAT,\n",
    "    \"2022-09-30\" FLOAT,\n",
    "    \"2022-10-31\" FLOAT,\n",
    "    \"2022-11-30\" FLOAT,\n",
    "    \"2022-12-31\" FLOAT,\n",
    "    \"2023-01-31\" FLOAT,\n",
    "    \"2023-02-28\" FLOAT,\n",
    "    \"2023-03-31\" FLOAT,\n",
    "    \"2023-04-30\" FLOAT,\n",
    "    \"2023-05-31\" FLOAT,\n",
    "    \"2023-06-30\" FLOAT,\n",
    "    \"2023-07-31\" FLOAT,\n",
    "    \"2023-08-31\" FLOAT,\n",
    "    \"2023-09-30\" FLOAT,\n",
    "    \"2023-10-31\" FLOAT,\n",
    "    \"2023-11-30\" FLOAT,\n",
    "    \"2023-12-31\" FLOAT,\n",
    "    \"2024-01-31\" FLOAT,\n",
    "    RegionName INT,\n",
    "    RegionID INT\n",
    ");\n",
    "\"\"\"\n",
    "Trees_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Tree\n",
    "(\n",
    "    tree_id TEXT PRIMARY KEY,\n",
    "    health TEXT,\n",
    "    zipcode TEXT,\n",
    "    status TEXT,\n",
    "    geometry GEOMETRY(Point, 4326),\n",
    "    spc_latin TEXT\n",
    ");\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(NYC_zip_codes_SCHEMA)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(ThreeOneOne_complaints_SCHEMA)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(Historical_Average_Rents_SCHEMA)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(Trees_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb40c899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Connect to your PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"Project_Database\",\n",
    "    user=\"sfm\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "with conn.cursor() as cur:\n",
    "    # Read and execute the schema files\n",
    "    with open(DATABASE_SCHEMA_FILE, 'r') as f:\n",
    "        sql_commands = f.read().split(';')\n",
    "        for command in sql_commands:\n",
    "            if command.strip() != '':\n",
    "                cur.execute(command)\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"Zip_Code\": taxi_data,\n",
    "    \"Complaint\": complaints_data_cleaned,\n",
    "    \"Rent\": rent_data_cleaned,\n",
    "    \"Tree\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "QUERY_DIRECTORY = \"queries\"\n",
    "\n",
    "def write_query_to_file(query, filename):\n",
    "    filepath = os.path.join(QUERY_DIRECTORY, filename)\n",
    "    with open(filepath, 'w') as file:\n",
    "        file.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef6fe0",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"complaints_by_zipcode.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT count(id) As \"Total Number of Complaints\", IncidentZip AS \"ZipCode\" FROM complaints\n",
    "Where CAST(CreatedDate AS DATE)>=\"2023-03-01\" and CAST(CreatedDate AS DATE)<='2024-02-29'\n",
    "GROUP BY IncidentZip\n",
    "ORDER BY count(id) desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d412f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = \"top_10_zipcodes_by_trees.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT count(tree_id) As \"Total Number of Trees\", zipcode AS \"ZipCode\" FROM trees GROUP BY zipcode\n",
    "ORDER BY count(tree_id) desc LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81001e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b6006",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = \"average_rent_in_top_tree_zipcodes.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT count(t.tree_id) As \"Total Number of Trees\", round(AVG(r.2024-01-31),2) AS \"Rent\" FROM trees t JOIN\n",
    "rent r on t.zipcode=r.RegionName\n",
    "Where t.zipcode in (SELECT zipcode FROM trees GROUP BY zipcode\n",
    "ORDER BY count(tree_id) desc LIMIT 10)\n",
    "GROUP BY t.zipcode\n",
    "ORDER BY count(t.tree_id)desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a419dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c9e011",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"rent_tree_complaint_correlation.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "(SELECT c.IncidentZip AS \"ZipCode\", round(AVG(r.2024-01-31),2) AS \"Average Rent\",count(t.tree_id) AS \"Total Number of Trees\", count(c.id) As \"Total Number of Complaints\" FROM complaints c\n",
    "RIGHTJOIN rent r on c.IncidentZip=r.RegionName LEFT JOIN trees t on t.zipcode=r.RegionName\n",
    "GROUP BY c.IncidentZip\n",
    "ORDER BY round(AVG(r.2024-01-31),2) desc LIMIT 5)\n",
    "UNION\n",
    "(SELECT c.IncidentZip AS \"ZipCode\", round(AVG(r.2024-01-31),2) AS \"Average Rent\",COUNT(COALESCE(t.tree_id, 0)) AS \"Total Number of Trees\", COUNT(COALESCE(c.id, 0)) As \"Total Number of Complaints\" FROM complaints c\n",
    "RIGHT JOIN rent r on c.IncidentZip=r.RegionName LEFT JOIN trees t on t.zipcode=r.RegionName\n",
    "GROUP BY c.IncidentZip\n",
    "ORDER BY round(AVG(r.2024-01-31),2) asc LIMIT 5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0119d48",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = \"most_greenery_join.sql\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT z.zipcode, COUNT(t.tree_id) AS total_trees\n",
    "FROM trees t\n",
    "JOIN zipcodes z ON ST_Contains(z.geom, ST_SetSRID(ST_MakePoint(t.longitude, t.Latitude), 4326))\n",
    "GROUP BY z.zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe57e7",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58259816",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shapely\n",
    "from shapely.geometry import Point\n",
    "import pyproj\n",
    "\n",
    "# Define the point and buffer radius in meters\n",
    "latitude, longitude = 40.80737875669467, -73.96253174434912\n",
    "buffer_radius_miles = 0.5\n",
    "\n",
    "# Convert buffer radius from miles to meters\n",
    "buffer_radius_meters = buffer_radius_miles * 1609.34\n",
    "\n",
    "# Define the coordinate reference system (CRS) for WGS 84 (EPSG:4326)\n",
    "crs_wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
    "\n",
    "# Create a point geometry\n",
    "point = Point(longitude, latitude)\n",
    "\n",
    "# Project the point to a local CRS in meters (e.g., EPSG:3857)\n",
    "crs_local = pyproj.CRS(\"EPSG:3857\")\n",
    "projected_point = pyproj.Transformer.from_crs(crs_wgs84, crs_local, always_xy=True).transform(point.x, point.y)\n",
    "\n",
    "# Create a buffer around the point\n",
    "buffered_point = Point(projected_point).buffer(buffer_radius_meters)\n",
    "\n",
    "# Convert the buffer to WKT format\n",
    "buffer_wkt = buffered_point.wkt\n",
    "\n",
    "QUERY_6_FILENAME = \"trees_within_half_mile_radius.sql\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT\n",
    "    tree_id, spc_latin, health, status, ST_AsText(the_geom) AS location\n",
    "FROM\n",
    "    trees\n",
    "WHERE\n",
    "    ST_DWithin(the_geom::geography, ST_SetSRID(ST_GeomFromText('POINT(-73.96253174434912 40.80737875669467)'), 4326)::geography, 804.67) = TRUE\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ae4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_6).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "psql --dbname groupNproject -f query.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    conn = sqlite3.connect('Project_Database.db')\n",
    "    \n",
    "    # Define your SQL query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT count(id) As \"Total Number of Complaints\", complaint_type\"Type\" FROM complaints\n",
    "    Where CAST(created_date AS DATE)>=\"2023-03-01\" and CAST(created_date AS DATE)<='2024-02-29'\n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY count(id) desc\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and fetch the results into a DataFrame\n",
    "    data = pd.read_sql_query(sql_query, conn)\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_1(dataframe):\n",
    "    conn = sqlite3.connect('Project_Database.db')\n",
    "    dates = pd.date_range(start='2023-03-01', end='2024-02-29')\n",
    "    data = []\n",
    "    for complaint_type in dataframe['complaint_type']:\n",
    "        sql_query = f\"\"\"\n",
    "        SELECT created_date, COUNT(id) AS daily_complaints\n",
    "        FROM complaints\n",
    "        WHERE created_date BETWEEN '2023-03-01' AND '2024-02-29'\n",
    "        AND complaint_type = '{complaint_type}'\n",
    "        GROUP BY created_date\n",
    "        \"\"\"\n",
    "        df = pd.read_sql_query(sql_query, conn)\n",
    "        df.set_index('created_date', inplace=True)\n",
    "        data.append(df.reindex(dates).fillna(0)['daily_complaints'])\n",
    "    \n",
    "    # Calculate the total number of complaints for the top 3 complaint types for each day\n",
    "    total_complaints = sum(data)\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(dates, total_complaints, label='Total Complaints', color='black', linewidth=2, linestyle='--')\n",
    "    plt.title('Number of Complaints per Day for Top 3 Complaint Types')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Complaint Type', loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual1_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(visual1_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87416880",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e267c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    conn = sqlite3.connect('Project_Database.db')\n",
    "    \n",
    "    # Define your SQL query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT count(id) As \"Total Number of Complaints\", complaint_type\"Type\" FROM complaints\n",
    "    Where CAST(created_date AS DATE)>=\"2023-03-01\" and CAST(created_date AS DATE)<='2024-02-29' and IncidentZip=10027\n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY count(id) desc\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and fetch the results into a DataFrame\n",
    "    data = pd.read_sql_query(sql_query, conn)\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_2(visual2_dataframe):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Total Number of Complaints', y='Type', data=visual2_dataframe, palette='viridis')\n",
    "    plt.title('Top 10 Complaint Types in Zip Code 10027 (Mar 1, 2022 - Feb 29, 2024)')\n",
    "    plt.xlabel('Total Number of Complaints')\n",
    "    plt.ylabel('Complaint Type')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual2_dataframe = get_data_for_visual_2()\n",
    "plot_visual_2(visual2_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc132dae",
   "metadata": {},
   "source": [
    "### Visualization 3 (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d85a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    conn = sqlite3.connect('Project_Database.db')\n",
    "    \n",
    "    # Define your SQL query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT count(id) As \"Total Number of Complaints\", complaint_type\"Type\" FROM complaints\n",
    "    Where CAST(created_date AS DATE)>=\"2023-03-01\" and CAST(created_date AS DATE)<='2024-02-29' and IncidentZip=10027\n",
    "    \n",
    "    GROUP BY complaint_type\n",
    "    ORDER BY count(id) desc\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and fetch the results into a DataFrame\n",
    "    data = pd.read_sql_query(sql_query, conn)\n",
    "    \n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62280f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855dae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual2_dataframe = get_data_for_visual_2()\n",
    "plot_visual_2(visual2_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e707712",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb3cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0eb139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa36e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31b51836",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667434b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68137177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "febb3fbd",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaf093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd14bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d2559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
